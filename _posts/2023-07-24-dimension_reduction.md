---
title : "Dimension Reduction"
excerpt : "차원 축소에 대한 내용을 담고 있고, linear dimension reduction은 PCA, non-linear dimension reduction는 VQA를 통해 설명 하였다.. "

categories: 
  - dimension_reduction
  - image_embedding

tags:
  - [Linear_Algebra, Machine_Learning, Deep_Learning, Dimension_Reduction, Image_Embedding]
  
toc: true
toc_sticky: true

date: 2023-07-24
last_modified_at: 2023-07-24
---

papers : J.E.Hinton, R.R.Salakhutdinov, "Reducing the Dimensionality of Data with Neural Networks", Science, 2006

#### Abstract

어떤 task를 함에 있어서, 제공하는 data는 우리가 활용하기 적합한 차원과 분포를 띄고 있는가? 라는 물음을 시작으로 차원 축소에 대해서 소개해 보았습니다.
보시다가 궁금증이나 틀린부분은 댓글로 달아주시면 감사하겠습니다.

### Reference

[colah Visualizing MNIST BLOG](https://colah.github.io/posts/2014-10-Visualizing-MNIST/​)

[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)​​
: Diederik P Kingma, Max Welling, arxiv

[A Tutorial on Principal Component Analysis](​​https://arxiv.org/abs/1404.1100​​)
: Jonathon Shlens, arxiv

[Hands On ML books github](https://github.com/ExcelsiorCJH/Hands-On-ML/​​)

[이활석님의 Autoencoder](https://www.slideshare.net/NaverEngineering/ss-96581209​​)

[scikit-learn manifold](https://scikit-learn.org/stable/modules/manifold.html#manifold​​)

[AAILab Kaist youtube ](https://www.youtube.com/@aailabkaist6236/playlists​​)

[naver d2](https://www.youtube.com/@naverd2848/playlists​​)

[SNE](​https://proceedings.neurips.cc/paper/2002/hash/6150ccc6069bea6b5716254057a194ef- Abstract.html​)
:Geoffrey E. Hinton, Sam Roweis

[t-SNE](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf?fbcl)
:Geoffrey E. Hinton


​
## PDF Document

<iframe src="../paper/Dimension/TechTalkCFP_dimension_reduction.pdf" width="100%" height="800px">
  <p>Unable to display PDF. Click <a href="../paper/Dimension/TechTalkCFP_dimension_reduction.pdf">here</a> to download it.</p>
</iframe>

<iframe src="../paper/CNN/ghost.pdf" width="100%" height="800px">
  <p>Unable to display PDF. Click <a href="../paper/CNN/ghost.pdf">here</a> to download it.</p>
</iframe>